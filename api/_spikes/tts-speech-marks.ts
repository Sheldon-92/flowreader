/**
 * Spike: TTS Speech Marks + å¥çº§å¯¹é½åŸå‹
 * 
 * éªŒè¯å…³é”®æŠ€æœ¯å‡è®¾ï¼š
 * 1. Amazon Polly Speech Marks çš„ç²¾åº¦å’Œå¯ç”¨æ€§
 * 2. å¥çº§æ–‡æœ¬åˆ†å‰²çš„å‡†ç¡®æ€§
 * 3. éŸ³é¢‘ä¸æ–‡æœ¬åŒæ­¥çš„å»¶è¿Ÿå’Œç²¾åº¦
 * 4. å®¢æˆ·ç«¯æ’­æ”¾ä¸é«˜äº®åŒæ­¥çš„æ€§èƒ½
 */

import { PollyClient, SynthesizeSpeechCommand } from '@aws-sdk/client-polly';

// æ¨¡æ‹Ÿé…ç½® - å®é™…ä½¿ç”¨æ—¶ä»ç¯å¢ƒå˜é‡è·å–
const mockConfig = {
  region: process.env.AWS_REGION || 'us-east-1',
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID || 'mock-key',
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || 'mock-secret'
  }
};

// å¥å­åˆ†å‰²å™¨ - ä½¿ç”¨ Intl.Segmenter (ç°ä»£æµè§ˆå™¨æ”¯æŒ)
export class SentenceSegmenter {
  private segmenter: Intl.Segmenter;

  constructor(locale: string = 'en-US') {
    this.segmenter = new Intl.Segmenter(locale, { 
      granularity: 'sentence' 
    });
  }

  segment(text: string): Array<{ text: string; start: number; end: number }> {
    const segments = Array.from(this.segmenter.segment(text));
    
    return segments.map(segment => ({
      text: segment.segment.trim(),
      start: segment.index,
      end: segment.index + segment.segment.length
    })).filter(seg => seg.text.length > 0);
  }
}

// Speech Marks ç”Ÿæˆå™¨
export class SpeechMarksGenerator {
  private polly: PollyClient;

  constructor() {
    // åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™å°†ä½¿ç”¨çœŸå®çš„AWSå‡­è¯
    this.polly = new PollyClient(mockConfig);
  }

  async generateSpeechMarks(
    text: string,
    voiceId: string = 'Joanna',
    engine: string = 'neural'
  ): Promise<{
    audioUrl: string;
    speechMarks: Array<{
      type: 'sentence' | 'word' | 'ssml';
      start: number;
      end: number;
      time: number;
      value: string;
    }>;
  }> {
    try {
      // ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
      const audioCommand = new SynthesizeSpeechCommand({
        Text: text,
        OutputFormat: 'mp3',
        VoiceId: voiceId,
        Engine: engine,
        SampleRate: '22050'
      });

      // ç”Ÿæˆ Speech Marks (å¥çº§)
      const marksCommand = new SynthesizeSpeechCommand({
        Text: text,
        OutputFormat: 'json',
        VoiceId: voiceId,
        Engine: engine,
        SpeechMarkTypes: ['sentence', 'word']
      });

      // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„ Polly API
      // const [audioResponse, marksResponse] = await Promise.all([
      //   this.polly.send(audioCommand),
      //   this.polly.send(marksCommand)
      // ]);

      // ç›®å‰è¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºéªŒè¯æ¶æ„
      return {
        audioUrl: 'mock-audio-url.mp3',
        speechMarks: this.generateMockSpeechMarks(text)
      };
    } catch (error) {
      console.error('Speech marks generation failed:', error);
      throw new Error(`TTS generation failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  private generateMockSpeechMarks(text: string) {
    // æ¨¡æ‹Ÿ Speech Marks æ•°æ®ç”¨äºåŸå‹éªŒè¯
    const segmenter = new SentenceSegmenter();
    const sentences = segmenter.segment(text);
    
    const speechMarks = [];
    let currentTime = 0;
    
    for (const sentence of sentences) {
      // å¥çº§æ ‡è®°
      speechMarks.push({
        type: 'sentence' as const,
        start: sentence.start,
        end: sentence.end,
        time: currentTime,
        value: sentence.text
      });
      
      // æ¨¡æ‹Ÿå•è¯çº§æ ‡è®°ï¼ˆç®€åŒ–ç‰ˆï¼‰
      const words = sentence.text.split(/\s+/);
      let wordStart = sentence.start;
      
      for (const word of words) {
        if (word.trim()) {
          speechMarks.push({
            type: 'word' as const,
            start: wordStart,
            end: wordStart + word.length,
            time: currentTime,
            value: word
          });
          
          // å‡è®¾æ¯ä¸ªå•è¯éœ€è¦ 0.4 ç§’ (150 WPM)
          currentTime += 400;
          wordStart += word.length + 1; // +1 for space
        }
      }
      
      // å¥å­é—´åœé¡¿
      currentTime += 200;
    }
    
    return speechMarks;
  }
}

// éŸ³é¢‘åŒæ­¥å¼•æ“
export class AudioSyncEngine {
  private currentSentenceIndex: number = 0;
  private currentWordIndex: number = 0;
  private speechMarks: Array<any> = [];
  private audio: HTMLAudioElement | null = null;
  private animationFrame: number | null = null;

  constructor() {}

  initialize(audioUrl: string, speechMarks: Array<any>): Promise<void> {
    return new Promise((resolve, reject) => {
      this.speechMarks = speechMarks;
      this.audio = new Audio(audioUrl);
      
      this.audio.addEventListener('loadeddata', () => {
        resolve();
      });
      
      this.audio.addEventListener('error', (e) => {
        reject(new Error(`Audio load failed: ${e}`));
      });
      
      this.audio.load();
    });
  }

  play(onSentenceHighlight?: (sentenceIndex: number, sentence: string) => void): void {
    if (!this.audio) return;
    
    this.audio.play();
    
    const updateHighlight = () => {
      if (!this.audio || this.audio.paused) return;
      
      const currentTime = this.audio.currentTime * 1000; // Convert to milliseconds
      
      // æ‰¾åˆ°å½“å‰åº”è¯¥é«˜äº®çš„å¥å­
      const currentSentence = this.speechMarks
        .filter(mark => mark.type === 'sentence')
        .find((mark, index) => {
          const nextMark = this.speechMarks
            .filter(m => m.type === 'sentence')[index + 1];
          
          return currentTime >= mark.time && 
                 (!nextMark || currentTime < nextMark.time);
        });
      
      if (currentSentence && onSentenceHighlight) {
        const sentenceIndex = this.speechMarks
          .filter(mark => mark.type === 'sentence')
          .indexOf(currentSentence);
          
        if (sentenceIndex !== this.currentSentenceIndex) {
          this.currentSentenceIndex = sentenceIndex;
          onSentenceHighlight(sentenceIndex, currentSentence.value);
        }
      }
      
      this.animationFrame = requestAnimationFrame(updateHighlight);
    };
    
    updateHighlight();
  }

  pause(): void {
    if (this.audio) {
      this.audio.pause();
    }
    if (this.animationFrame) {
      cancelAnimationFrame(this.animationFrame);
    }
  }

  seekTo(sentenceIndex: number): void {
    if (!this.audio || !this.speechMarks) return;
    
    const sentenceMarks = this.speechMarks.filter(mark => mark.type === 'sentence');
    const targetSentence = sentenceMarks[sentenceIndex];
    
    if (targetSentence) {
      this.audio.currentTime = targetSentence.time / 1000; // Convert to seconds
      this.currentSentenceIndex = sentenceIndex;
    }
  }

  getCurrentPosition(): { sentenceIndex: number; timeMs: number } {
    return {
      sentenceIndex: this.currentSentenceIndex,
      timeMs: this.audio ? this.audio.currentTime * 1000 : 0
    };
  }

  destroy(): void {
    this.pause();
    if (this.audio) {
      this.audio.src = '';
      this.audio = null;
    }
  }
}

// Spike éªŒè¯å‡½æ•°
export async function validateTTSSpeechMarks(): Promise<{
  success: boolean;
  results: {
    segmentation_accuracy: number;
    speech_marks_generation: boolean;
    sync_latency_ms: number;
    performance_score: number;
  };
  errors: string[];
}> {
  const errors: string[] = [];
  let success = true;
  
  try {
    // æµ‹è¯•æ–‡æœ¬
    const testText = `
      FlowReader is a revolutionary reading application that combines traditional text reading with modern AI assistance. 
      It provides seamless audio-text synchronization for an enhanced reading experience. 
      Users can highlight text, take notes, and engage with AI for deeper understanding.
    `.trim();
    
    console.log('ğŸ§ª Starting TTS Speech Marks Spike validation...');
    
    // 1. æµ‹è¯•å¥å­åˆ†å‰²å‡†ç¡®æ€§
    const segmenter = new SentenceSegmenter();
    const sentences = segmenter.segment(testText);
    
    console.log('ğŸ“ Sentence segmentation results:', sentences.length, 'sentences');
    
    // éªŒè¯åˆ†å‰²åˆç†æ€§ (åº”è¯¥æœ‰3ä¸ªå¥å­)
    const segmentationAccuracy = sentences.length === 3 ? 100 : 
      (Math.max(0, 100 - Math.abs(sentences.length - 3) * 20));
    
    // 2. æµ‹è¯• Speech Marks ç”Ÿæˆ
    const generator = new SpeechMarksGenerator();
    const startTime = Date.now();
    
    const result = await generator.generateSpeechMarks(testText);
    const generationTime = Date.now() - startTime;
    
    console.log('ğŸ”Š Speech marks generated:', result.speechMarks.length, 'marks');
    console.log('â±ï¸  Generation time:', generationTime, 'ms');
    
    // 3. æµ‹è¯•åŒæ­¥å¼•æ“åˆå§‹åŒ–
    const syncEngine = new AudioSyncEngine();
    
    // åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šåˆå§‹åŒ–çœŸå®çš„éŸ³é¢‘
    // await syncEngine.initialize(result.audioUrl, result.speechMarks);
    
    // 4. æ€§èƒ½è¯„ä¼°
    const performanceScore = generationTime < 5000 ? 100 : 
      Math.max(0, 100 - (generationTime - 5000) / 100);
    
    console.log('âœ… TTS Speech Marks Spike validation completed');
    
    return {
      success: true,
      results: {
        segmentation_accuracy: segmentationAccuracy,
        speech_marks_generation: true,
        sync_latency_ms: generationTime,
        performance_score: performanceScore
      },
      errors
    };
    
  } catch (error) {
    console.error('âŒ TTS Speech Marks Spike validation failed:', error);
    errors.push(error instanceof Error ? error.message : 'Unknown error');
    success = false;
    
    return {
      success: false,
      results: {
        segmentation_accuracy: 0,
        speech_marks_generation: false,
        sync_latency_ms: 0,
        performance_score: 0
      },
      errors
    };
  }
}

// å¯¼å‡ºéªŒè¯ç»“æœæ£€æŸ¥å‡½æ•°
export function evaluateSpikeResults(results: any): {
  recommendation: 'PROCEED' | 'MODIFY' | 'BLOCK';
  issues: string[];
  nextActions: string[];
} {
  const issues: string[] = [];
  const nextActions: string[] = [];
  
  // è¯„ä¼°åˆ†å‰²å‡†ç¡®æ€§
  if (results.segmentation_accuracy < 80) {
    issues.push('Sentence segmentation accuracy below 80%');
    nextActions.push('Improve sentence boundary detection algorithm');
  }
  
  // è¯„ä¼°æ€§èƒ½
  if (results.sync_latency_ms > 10000) {
    issues.push('TTS generation too slow (>10s)');
    nextActions.push('Optimize Polly API calls or implement caching');
  }
  
  // è¯„ä¼°æ•´ä½“æ€§èƒ½åˆ†æ•°
  if (results.performance_score < 70) {
    issues.push('Overall performance score below acceptable threshold');
    nextActions.push('Review and optimize critical path performance');
  }
  
  // ç¡®å®šå»ºè®®
  let recommendation: 'PROCEED' | 'MODIFY' | 'BLOCK' = 'PROCEED';
  
  if (!results.speech_marks_generation) {
    recommendation = 'BLOCK';
    nextActions.push('Fix Speech Marks generation before proceeding');
  } else if (issues.length > 2) {
    recommendation = 'MODIFY';
    nextActions.push('Address major issues before full implementation');
  } else if (issues.length > 0) {
    recommendation = 'PROCEED';
    nextActions.push('Monitor and improve during development');
  }
  
  return { recommendation, issues, nextActions };
}